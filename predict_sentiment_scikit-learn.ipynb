{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "In this notebook, we try to predict whether a product review has positive or negative sentiment using logistic regression.\n",
    "\n",
    "We'll use a dataset of amazon baby products.\n",
    "\n",
    "We'll work with text data and bag-of-word representations for feature extraction. A tf-idf model will also be implemented.\n",
    "\n",
    "### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = pd.read_csv('amazon_baby.csv')\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "1  it came early and was not disappointed. i love...       5          1  \n",
       "2  Very soft and comfortable and warmer than it l...       5          1  \n",
       "3  This is a product well worth the purchase.  I ...       5          1  \n",
       "4  All of my kids have cried non-stop when I trie...       5          1  \n",
       "5  When the Binky Fairy came to our house, we did...       5          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "products = products[products['rating'] != 3] # Remove reviews with a core of 3.\n",
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1) # add a sentiment column. 1 if positive, -1 if negative\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(products, train_size = 0.8, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1. Classifier using logistic regression and all words in the corpus\n",
    "\n",
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "word_count = vectorizer.fit_transform(train_data['review'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moodel definition\n",
    "classifier = linear_model.LogisticRegression() \n",
    "targets = train_data['sentiment'].values\n",
    "classifier.fit(word_count, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1]\n",
      "[[ 0.00722719  0.99277281]\n",
      " [ 0.67636933  0.32363067]]\n"
     ]
    }
   ],
   "source": [
    "# Example review classification\n",
    "examples = ['I love it! Perfect for my cloth wipes!', \n",
    "            \"it was awful. i didn't like it all\"]\n",
    "example_counts = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "predictions_proba = classifier.predict_proba(example_counts)\n",
    "print predictions\n",
    "print predictions_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 ..., -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# Predict sentiment on test data\n",
    "test_data_word_count = vectorizer.transform(test_data['review'].values)\n",
    "predictions_test_data = classifier.predict(test_data_word_count)\n",
    "print predictions_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.33042862  0.15670811  0.00949425 ...,  0.00519866  0.03212715\n",
      "   0.00320389]]\n"
     ]
    }
   ],
   "source": [
    "# Print coefficients\n",
    "coefficients = classifier.coef_ \n",
    "print coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93166621690504037"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of the model on test data\n",
    "accuracy_score(test_data['sentiment'], predictions_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.72935680e-03   9.94270643e-01]\n",
      " [  8.49456024e-01   1.50543976e-01]\n",
      " [  9.96582299e-06   9.99990034e-01]\n",
      " ..., \n",
      " [  6.63944486e-01   3.36055514e-01]\n",
      " [  2.94171635e-04   9.99705828e-01]\n",
      " [  1.17445221e-01   8.82554779e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Probabilities \n",
    "predictions_proba_test_data = classifier.predict_proba(test_data_word_count)\n",
    "print predictions_proba_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2. Simple classifier (only 20 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(vocabulary = significant_words)\n",
    "word_count2 = vectorizer2.fit_transform(train_data['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier2 = linear_model.LogisticRegression()\n",
    "classifier2.fit(word_count2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "test_data_word_count2 = vectorizer2.transform(test_data['review'].values)\n",
    "predictions_test_data2 = classifier2.predict(test_data_word_count2)\n",
    "print predictions_test_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.36258866  0.95188095  1.16567375  0.07084353  0.50704601  1.48341667\n",
      "   1.71173377  0.51955938  0.20361731  0.06965207 -1.6163692  -0.13500917\n",
      "  -0.52166598 -2.00558081 -2.39622512 -0.63473968 -0.32338326 -0.87424943\n",
      "  -0.34257254 -2.11117408]]\n"
     ]
    }
   ],
   "source": [
    "coefficients2 = classifier2.coef_ \n",
    "print coefficients2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86489160744805249"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_data['sentiment'], predictions_test_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3. Classifier with tfidf transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "word_count3 = tfidf_vectorizer.fit_transform(train_data['review'].values)\n",
    "classifier3 = linear_model.LogisticRegression()\n",
    "classifier3.fit(word_count3, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 ..., -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "test_data_word_count3 = tfidf_vectorizer.transform(test_data['review'].values)\n",
    "predictions_test_data3 = classifier3.predict(test_data_word_count3)\n",
    "print predictions_test_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.4450426  -0.02209531  0.03779681 ...,  0.01203408  0.00629359\n",
      "   0.00639339]]\n"
     ]
    }
   ],
   "source": [
    "coefficients3 = classifier3.coef_ \n",
    "print coefficients3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93292554945878681"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_data['sentiment'], predictions_test_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93292554945878681"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier3.score(test_data_word_count3,test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best and worst words in Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_words = pd.DataFrame.from_dict(vectorizer.vocabulary_, orient = 'index')\n",
    "list_of_words.reset_index(inplace=True)\n",
    "list_of_words.set_index(0, inplace = True)\n",
    "list_of_words = list_of_words.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_coefficients = pd.DataFrame(data = coefficients)\n",
    "list_of_coefficients = list_of_coefficients.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.merge(list_of_words, list_of_coefficients, left_index = True, right_index = True).sort_values(by=0, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29536</th>\n",
       "      <td>lifesaver</td>\n",
       "      <td>2.320043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45730</th>\n",
       "      <td>skeptical</td>\n",
       "      <td>2.291736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50508</th>\n",
       "      <td>thankful</td>\n",
       "      <td>2.261218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11629</th>\n",
       "      <td>code</td>\n",
       "      <td>2.086964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12426</th>\n",
       "      <td>con</td>\n",
       "      <td>2.073053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42703</th>\n",
       "      <td>rich</td>\n",
       "      <td>2.070038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41735</th>\n",
       "      <td>relax</td>\n",
       "      <td>2.005231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30017</th>\n",
       "      <td>locate</td>\n",
       "      <td>1.998506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19247</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1.956949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56703</th>\n",
       "      <td>worry</td>\n",
       "      <td>1.956884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>downside</td>\n",
       "      <td>1.943692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38017</th>\n",
       "      <td>pleasantly</td>\n",
       "      <td>1.937360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>applying</td>\n",
       "      <td>1.920613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37511</th>\n",
       "      <td>pics</td>\n",
       "      <td>1.911307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32128</th>\n",
       "      <td>minor</td>\n",
       "      <td>1.876783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>35lbs</td>\n",
       "      <td>1.817029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56546</th>\n",
       "      <td>wonderfully</td>\n",
       "      <td>1.816528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37087</th>\n",
       "      <td>perfect</td>\n",
       "      <td>1.805100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24769</th>\n",
       "      <td>highly</td>\n",
       "      <td>1.790139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45594</th>\n",
       "      <td>sipper</td>\n",
       "      <td>1.766264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index         0\n",
       "0                           \n",
       "29536    lifesaver  2.320043\n",
       "45730    skeptical  2.291736\n",
       "50508     thankful  2.261218\n",
       "11629         code  2.086964\n",
       "12426          con  2.073053\n",
       "42703         rich  2.070038\n",
       "41735        relax  2.005231\n",
       "30017       locate  1.998506\n",
       "19247    excellent  1.956949\n",
       "56703        worry  1.956884\n",
       "16997     downside  1.943692\n",
       "38017   pleasantly  1.937360\n",
       "4801      applying  1.920613\n",
       "37511         pics  1.911307\n",
       "32128        minor  1.876783\n",
       "1413         35lbs  1.817029\n",
       "56546  wonderfully  1.816528\n",
       "37087      perfect  1.805100\n",
       "24769       highly  1.790139\n",
       "45594       sipper  1.766264"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9094</th>\n",
       "      <td>bummer</td>\n",
       "      <td>-2.047620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9093</th>\n",
       "      <td>bummed</td>\n",
       "      <td>-2.070134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42511</th>\n",
       "      <td>returned</td>\n",
       "      <td>-2.085465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42514</th>\n",
       "      <td>returning</td>\n",
       "      <td>-2.099537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38394</th>\n",
       "      <td>poor</td>\n",
       "      <td>-2.124387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28861</th>\n",
       "      <td>lame</td>\n",
       "      <td>-2.135806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12454</th>\n",
       "      <td>concept</td>\n",
       "      <td>-2.181294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41377</th>\n",
       "      <td>rediculous</td>\n",
       "      <td>-2.208805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37651</th>\n",
       "      <td>pinches</td>\n",
       "      <td>-2.238534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16099</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>-2.276401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53898</th>\n",
       "      <td>unusable</td>\n",
       "      <td>-2.329451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54181</th>\n",
       "      <td>useless</td>\n",
       "      <td>-2.343474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26388</th>\n",
       "      <td>ineffective</td>\n",
       "      <td>-2.347238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38399</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-2.497988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38231</th>\n",
       "      <td>pointless</td>\n",
       "      <td>-2.535068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50755</th>\n",
       "      <td>theory</td>\n",
       "      <td>-2.561746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56725</th>\n",
       "      <td>worthless</td>\n",
       "      <td>-2.569590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16103</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>-2.569614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56716</th>\n",
       "      <td>worst</td>\n",
       "      <td>-2.587703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16474</th>\n",
       "      <td>dissapointed</td>\n",
       "      <td>-2.859194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index         0\n",
       "0                             \n",
       "9094          bummer -2.047620\n",
       "9093          bummed -2.070134\n",
       "42511       returned -2.085465\n",
       "42514      returning -2.099537\n",
       "38394           poor -2.124387\n",
       "28861           lame -2.135806\n",
       "12454        concept -2.181294\n",
       "41377     rediculous -2.208805\n",
       "37651        pinches -2.238534\n",
       "16099   disappointed -2.276401\n",
       "53898       unusable -2.329451\n",
       "54181        useless -2.343474\n",
       "26388    ineffective -2.347238\n",
       "38399         poorly -2.497988\n",
       "38231      pointless -2.535068\n",
       "50755         theory -2.561746\n",
       "56725      worthless -2.569590\n",
       "16103  disappointing -2.569614\n",
       "56716          worst -2.587703\n",
       "16474   dissapointed -2.859194"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best and worst words in Model 3 (tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30339</th>\n",
       "      <td>love</td>\n",
       "      <td>14.075142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23302</th>\n",
       "      <td>great</td>\n",
       "      <td>12.604814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17745</th>\n",
       "      <td>easy</td>\n",
       "      <td>11.472226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37087</th>\n",
       "      <td>perfect</td>\n",
       "      <td>10.659853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30368</th>\n",
       "      <td>loves</td>\n",
       "      <td>9.758368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37101</th>\n",
       "      <td>perfectly</td>\n",
       "      <td>7.465394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7231</th>\n",
       "      <td>best</td>\n",
       "      <td>7.401948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24769</th>\n",
       "      <td>highly</td>\n",
       "      <td>7.029631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24100</th>\n",
       "      <td>happy</td>\n",
       "      <td>6.853185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22664</th>\n",
       "      <td>glad</td>\n",
       "      <td>6.215139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29898</th>\n",
       "      <td>little</td>\n",
       "      <td>6.209920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19247</th>\n",
       "      <td>excellent</td>\n",
       "      <td>5.941972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19193</th>\n",
       "      <td>exactly</td>\n",
       "      <td>5.797376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33947</th>\n",
       "      <td>nice</td>\n",
       "      <td>5.698685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>awesome</td>\n",
       "      <td>5.538482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38020</th>\n",
       "      <td>pleased</td>\n",
       "      <td>5.472975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20650</th>\n",
       "      <td>fits</td>\n",
       "      <td>5.375898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56677</th>\n",
       "      <td>works</td>\n",
       "      <td>5.344433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55736</th>\n",
       "      <td>well</td>\n",
       "      <td>5.242756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48751</th>\n",
       "      <td>sturdy</td>\n",
       "      <td>5.191480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index          0\n",
       "0                          \n",
       "30339       love  14.075142\n",
       "23302      great  12.604814\n",
       "17745       easy  11.472226\n",
       "37087    perfect  10.659853\n",
       "30368      loves   9.758368\n",
       "37101  perfectly   7.465394\n",
       "7231        best   7.401948\n",
       "24769     highly   7.029631\n",
       "24100      happy   6.853185\n",
       "22664       glad   6.215139\n",
       "29898     little   6.209920\n",
       "19247  excellent   5.941972\n",
       "19193    exactly   5.797376\n",
       "33947       nice   5.698685\n",
       "5766     awesome   5.538482\n",
       "38020    pleased   5.472975\n",
       "20650       fits   5.375898\n",
       "56677      works   5.344433\n",
       "55736       well   5.242756\n",
       "48751     sturdy   5.191480"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_words = pd.DataFrame.from_dict(tfidf_vectorizer.vocabulary_, orient = 'index')\n",
    "list_of_words.reset_index(inplace=True)\n",
    "list_of_words.set_index(0, inplace = True)\n",
    "list_of_words = list_of_words.sort_index()\n",
    "\n",
    "list_of_coefficients = pd.DataFrame(data = coefficients3)\n",
    "list_of_coefficients = list_of_coefficients.transpose()\n",
    "\n",
    "results = pd.merge(list_of_words, list_of_coefficients, left_index = True, right_index = True).sort_values(by=0, ascending = False)\n",
    "\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32582</th>\n",
       "      <td>money</td>\n",
       "      <td>-5.073166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12454</th>\n",
       "      <td>concept</td>\n",
       "      <td>-5.553375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26007</th>\n",
       "      <td>impossible</td>\n",
       "      <td>-5.570638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>broke</td>\n",
       "      <td>-5.576125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53450</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>-5.609352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6512</th>\n",
       "      <td>barely</td>\n",
       "      <td>-5.723863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25211</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-5.848213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25696</th>\n",
       "      <td>idea</td>\n",
       "      <td>-5.886024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38399</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-6.066991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50389</th>\n",
       "      <td>terrible</td>\n",
       "      <td>-6.155540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56716</th>\n",
       "      <td>worst</td>\n",
       "      <td>-6.963295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16103</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>-6.988762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42508</th>\n",
       "      <td>return</td>\n",
       "      <td>-7.672271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38394</th>\n",
       "      <td>poor</td>\n",
       "      <td>-7.712200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42514</th>\n",
       "      <td>returning</td>\n",
       "      <td>-7.720294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54181</th>\n",
       "      <td>useless</td>\n",
       "      <td>-7.843751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55429</th>\n",
       "      <td>waste</td>\n",
       "      <td>-7.970957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42511</th>\n",
       "      <td>returned</td>\n",
       "      <td>-8.080088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16099</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>-10.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34334</th>\n",
       "      <td>not</td>\n",
       "      <td>-10.581155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index          0\n",
       "0                              \n",
       "32582          money  -5.073166\n",
       "12454        concept  -5.553375\n",
       "26007     impossible  -5.570638\n",
       "8772           broke  -5.576125\n",
       "53450  unfortunately  -5.609352\n",
       "6512          barely  -5.723863\n",
       "25211       horrible  -5.848213\n",
       "25696           idea  -5.886024\n",
       "38399         poorly  -6.066991\n",
       "50389       terrible  -6.155540\n",
       "56716          worst  -6.963295\n",
       "16103  disappointing  -6.988762\n",
       "42508         return  -7.672271\n",
       "38394           poor  -7.712200\n",
       "42514      returning  -7.720294\n",
       "54181        useless  -7.843751\n",
       "55429          waste  -7.970957\n",
       "42511       returned  -8.080088\n",
       "16099   disappointed -10.000892\n",
       "34334            not -10.581155"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
